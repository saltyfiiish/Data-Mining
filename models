import pandas as pd
import time
import matplotlib.pyplot as plt
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc
from sklearn.svm import LinearSVC
from sklearn.model_selection import GridSearchCV
from sklearn.calibration import CalibratedClassifierCV

# 1. Load and preprocess data

# Extract column names
column_names = []
with open('adult.names', 'r') as file:
    for line in file:
        if not line.startswith('|') and ':' in line:
            column_name = line.split(':')[0].strip()
            column_names.append(column_name)
column_names.append('income')

# Read datasets
data = pd.read_csv('adult.data', header=None, names=column_names, na_values='?', skipinitialspace=True)
data_test = pd.read_csv('adult.test', header=None, names=column_names, na_values='?', skiprows=1, skipinitialspace=True)

for column in data_test.columns[1:]:
    data_test[column] = data_test[column].astype(str).str.lstrip()
data_test['income'] = data_test['income'].str.replace('.', '', regex=False)

# Fill missing values with mode
missing_values = data.isnull().sum()
missing_columns = missing_values[missing_values > 0]
for column in missing_columns.index:
    if data[column].dtype == 'object':
        most_frequent = data[column].mode()[0]
        data[column] = data[column].fillna(most_frequent)
        data_test[column] = data_test[column].fillna(most_frequent)

print("Missing values handled.")

# Convert target variable
data['income'] = data['income'].map({'<=50K': 0, '>50K': 1})
data_test['income'] = data_test['income'].map({'<=50K': 0, '>50K': 1})

# One-Hot Encoding for categorical columns
categorical_columns = data.select_dtypes(include=['object']).columns
encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')

encoded_train = encoder.fit_transform(data[categorical_columns])
encoded_test = encoder.transform(data_test[categorical_columns])

encoded_train_df = pd.DataFrame(encoded_train, columns=encoder.get_feature_names_out(categorical_columns))
encoded_test_df = pd.DataFrame(encoded_test, columns=encoder.get_feature_names_out(categorical_columns))

encoded_train_df.index = data.index
encoded_test_df.index = data_test.index

# Merge encoded columns
data = pd.concat([data.drop(columns=categorical_columns), encoded_train_df], axis=1)
data_test = pd.concat([data_test.drop(columns=categorical_columns), encoded_test_df], axis=1)

print("One-Hot Encoding completed")

# Split into X, y
X_train = data.drop(columns=['income'])
y_train = data['income']
X_test = data_test.drop(columns=['income'])
y_test = data_test['income']

# 2. Standardization

scaler = StandardScaler()
X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns, index=X_train.index)
X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)

print("Standardization completed")

# 3. Random Forest
param_grid_rf = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2],
    'max_features': ['sqrt', 'log2']
}

rf_model = RandomForestClassifier(random_state=42)
grid_search_rf = GridSearchCV(
    estimator=rf_model,
    param_grid=param_grid_rf,
    scoring='f1',
    cv=3,
    n_jobs=-1,
    verbose=2
)

start_time = time.time()
grid_search_rf.fit(X_train, y_train)
rf_training_time = time.time() - start_time

best_rf = grid_search_rf.best_estimator_
print("Best RandomForest parameters:", grid_search_rf.best_params_)

start_time = time.time()
rf_predictions = best_rf.predict(X_test)
rf_prediction_time = time.time() - start_time

rf_accuracy = accuracy_score(y_test, rf_predictions)
rf_precision = precision_score(y_test, rf_predictions)
rf_recall = recall_score(y_test, rf_predictions)
rf_f1 = f1_score(y_test, rf_predictions)

print(f"Random Forest - Training time: {rf_training_time:.4f}s, Prediction time: {rf_prediction_time:.4f}s")
print(f"Random Forest - Accuracy: {rf_accuracy:.4f}, Precision: {rf_precision:.4f}, Recall: {rf_recall:.4f}, F1: {rf_f1:.4f}")

# 4. LinearSVC
param_grid_svm = {
    'C': [0.1, 1, 10],
    'class_weight': [None, 'balanced']
}

svc = LinearSVC(random_state=42, max_iter=5000)
grid_search_svm = GridSearchCV(
    estimator=svc,
    param_grid=param_grid_svm,
    scoring='f1',
    cv=3,
    n_jobs=-1,
    verbose=2
)

start_time = time.time()
grid_search_svm.fit(X_train, y_train)
svm_training_time = time.time() - start_time

best_svm = grid_search_svm.best_estimator_
print("Best LinearSVC parameters:", grid_search_svm.best_params_)

calibrated_svm = CalibratedClassifierCV(best_svm, cv='prefit')
calibrated_svm.fit(X_train, y_train)

start_time = time.time()
svm_predictions = calibrated_svm.predict(X_test)
svm_prediction_time = time.time() - start_time

svm_accuracy = accuracy_score(y_test, svm_predictions)
svm_precision = precision_score(y_test, svm_predictions)
svm_recall = recall_score(y_test, svm_predictions)
svm_f1 = f1_score(y_test, svm_predictions)

print(f"LinearSVC - Training time: {svm_training_time:.4f}s, Prediction time: {svm_prediction_time:.4f}s")
print(f"LinearSVC - Accuracy: {svm_accuracy:.4f}, Precision: {svm_precision:.4f}, Recall: {svm_recall:.4f}, F1: {svm_f1:.4f}")

# 5. ROC curve comparison
rf_probs = best_rf.predict_proba(X_test)[:, 1]
svm_probs = calibrated_svm.predict_proba(X_test)[:, 1]

rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_probs)
svm_fpr, svm_tpr, _ = roc_curve(y_test, svm_probs)

rf_roc_auc = auc(rf_fpr, rf_tpr)
svm_roc_auc = auc(svm_fpr, svm_tpr)

plt.figure()
plt.plot(rf_fpr, rf_tpr, label=f"Random Forest (AUC = {rf_roc_auc:.4f})")
plt.plot(svm_fpr, svm_tpr, label=f"LinearSVC (AUC = {svm_roc_auc:.4f})")
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve Comparison")
plt.legend(loc="lower right")
plt.savefig('roc_curve.png')
plt.close()

print("ROC curve saved as 'roc_curve.png'")
